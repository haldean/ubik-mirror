Compile-time Type Inference ============================================
Haldean Brown                                      First draft: Jun 2016
                                                  Last updated: Jun 2016

Status: Draft

------------------------------------------------------------------------

A key part of the Ubik compilation process is type checking and type
inference. Both of these two steps happen in the same AST pass, called
"inference"; despite it's name, it's also responsible for type checking.

Inference happens module-by-module; since all top-level definitions have
types specified on them, no cross-module inference must occur. The first
step for a module is to assign type variables to each expression in the
AST. The next step is to assign to some of those variables values that
represent known types (either because the associated expressions are
source literals or because they are externally imported, and thus we
know their signature). Next, we introduce constraints that the semanics
of the program introduce (i.e., "a b" must have a type equal to the type
of a applied to the type of b). Finally, we attempt to find an
assignment to variables that provides a "specific" type (i.e., a type
that does not have any dependence on further variables).

The first step is simple. We assign each node in the AST a unique type
variable. Let's take the following sample Ubik program:

    : infer-example
        ^ String -> Integer
        = \a -> {
            : y = concat a "hello"
            ! length y
        }

Which has the following expression-typevar mapping:

    t0    \a -> { : y = concat a "hello" ! humanize (length y) }
    t1    a
    t2    { : y = concat a "hello" ! humanize (length y) }
    t3    concat a "hello"
    t4    concat a
    t5    concat
    t6    a
    t7    "hello"
    t8    humanize (length y)
    t9    humanize
    t10   length y
    t11   length
    t12   y

And thus the first stage is complete. The next stage is to start
building our fact set. We first introduce type equality constraints for
literals whose types we know for sure:

    t7  = String

We can introduce another fact that represents our knowledge of the
top-level binding's type:

    t0  = String -> Integer
    t7  = String

Then, we can use our knowledge of the externally-imported functions
concat and length; since these are polymorphic, they introduce new type
variables. (I'll use the "<" character to mean "element-of", from now on)

    t0  = String -> Integer
    t5  = String -> String -> String
    t7  = String
    t9  = t12 -> String
    t11 = t13 -> Integer
    t12 < Printable
    t13 < HasLength

We also know about the types involved, and which type classes they're a
member of:

    t0  = String -> Integer
    t5  = String -> String -> String
    t7  = String
    t9  = t12 -> String
    t11 = t13 -> Integer
    t12 < Printable
    t13 < HasLength
    String < Printable
    String < HasLength

Okay, next phase. Now we introduce facts that are implied by the
semantics of the program:

    t0  = String -> Integer
    t2  = t0 t1
    t2  = t8
    t3  = t4 t7
    t4  = t5 t6
    t5  = String -> String -> String
    t6  = t1
    t7  = String
    t8  = t9 t10
    t9  = t12 -> String
    t10 = t11 t12
    t11 = t13 -> Integer
    t12 = t3
    t12 < Printable
    t13 < HasLength
    String < Printable
    String < HasLength

There is only one type that does not appear on the left-hand side of a
type assignment here: t1. This is because we do not know anything a
priori about t1 itself; we rely on the later solve step to handle
inferring its type from the top-level type, so that we do not need
global name resolution information during the interpretation phase.

The next step is reduction; our goal here is to produce specific
types and find any type disagreements, if they exist. We have a few
unification methods at our disposal. The notation here is:

    prerequisite 1 |
    prerequisite 2 |
    prerequisite 3 | conclusions

Which means that, if the prerequisites are all true, the given
conclusions can be drawn. We use uppercase letters to describe specific
types, and lowercase letters to describe type variables. Let's start
with two simple reduction rules

    - apply: unpacking function types:
            x0 = A -> B |
            x1 = x0 x2  |  x1 = B , x2 = A
    - trans: exploiting the transitive property of equality:
            x0 = x1 |
            x1 = x2 | x0 = x2

Using the apply rule, we can add new information about t1 and t2 (from
now on, new facts are marked with a *, and facts used to generate them
are marked with -):

  - t0  = String -> Integer
  - t2  = t0 t1
  * t1  = String
  * t2  = Integer

Similarly, we can hit these guys up:

  - t4  = t5 t6
  - t5  = String -> String -> String
  * t4  = String -> String
  * t6  = String

  - t8  = t9 t10
  - t9  = t12 -> String
  * t8  = String
  * t10 = t12

  - t10 = t11 t12
  - t11 = t13 -> Integer
  * t10 = Integer
  * t12 = t13

And now our full fact set looks like:

    t0  = String -> Integer
    t2  = t0 t1
    t1  = String
    t2  = Integer
    t2  = t8
    t3  = t4 t7
    t4  = t5 t6
    t5  = String -> String -> String
    t4  = String -> String
    t6  = String
    t6  = t1
    t7  = String
    t8  = t9 t10
    t9  = t12 -> String
    t8  = String
    t10 = t12
    t10 = t11 t12
    t11 = t13 -> Integer
    t10 = Integer
    t12 = t13
    t12 = t3
    t12 < Printable
    t13 < HasLength
    String < Printable
    String < HasLength

Oh look, we can apply more stuff (we already know that t7 is a string,
so it isn't produced here):

  - t3  = t4 t7
  - t4  = String -> String
  * t3  = String

Our goal is to assign to each variable a specific type. So far, we've
got these guys covered:

    t0  = String -> Integer
    t1  = String
    t2  = Integer
    t3  = String
    t4  = String -> String
    t5  = String -> String -> String
    t6  = String
    t7  = String
    t8  = String
    t10 = Integer

Which means we're missing t9, t11, and t12. t12 is easy; we apply
the transitive property to t12 = t3 and t3 = String to get t12 = String.
Now all we're left with is t9 and t11, which are both interesting
because they're the types of polymorphic functions. These are
interesting because, while technically we know the "full" type of these
functions because they're imported, we don't actually have a specific
type for them. 
